{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding f:\\interview\\acordao\\acordao_validator to sys.path\n",
      "Basic setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup, Path, and Imports\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import shutil # For cleaning up the test database directory\n",
    "import time\n",
    "\n",
    "# Configure logging for tests\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - RETRIEVER_TEST - %(levelname)s - %(message)s')\n",
    "\n",
    "# Add the 'src' directory to the Python path to find the modules\n",
    "module_path = os.path.abspath(os.path.join('..')) # Assumes notebook is in 'notebooks/' dir\n",
    "if module_path not in sys.path:\n",
    "    print(f\"Adding {module_path} to sys.path\")\n",
    "    sys.path.append(module_path)\n",
    "else:\n",
    "    print(f\"{module_path} already in sys.path\")\n",
    "\n",
    "print(\"Basic setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\interview\\acordao\\acordao_validator\\acordao\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported from indexer.\n",
      "Successfully imported from data_loader.\n",
      "Successfully imported from retriever.\n",
      "Successfully imported chromadb.\n",
      "\n",
      "Setup complete. Using test ChromaDB directory: f:\\interview\\acordao\\acordao_validator\\notebooks\\chroma_db_index\n",
      "Cleaning up existing test ChromaDB directory: f:\\interview\\acordao\\acordao_validator\\notebooks\\chroma_db_index\n",
      "No cached client found in retriever module to reset.\n",
      "Cleanup successful.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Imports, Constants, and Cleanup Helper\n",
    "\n",
    "# Standard library imports already done in Cell 1\n",
    "\n",
    "# --- Project Modules ---\n",
    "try:\n",
    "    # Need indexer to setup the DB for testing the retriever\n",
    "    from src.indexer import get_embedding_model, create_or_update_index\n",
    "    from src.indexer import CHROMA_PERSIST_DIR, CHROMA_COLLECTION_NAME, EMBEDDING_MODEL_NAME\n",
    "    print(\"Successfully imported from indexer.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR importing from indexer: {e}. Indexer tests might be needed first.\")\n",
    "    # Define fallbacks to avoid NameErrors, though tests will likely fail\n",
    "    get_embedding_model = None\n",
    "    create_or_update_index = None\n",
    "    CHROMA_PERSIST_DIR = os.path.join(\".\", \"chroma_db_retriever_test_index\") # Use separate test dir\n",
    "    CHROMA_COLLECTION_NAME = \"retriever_test_acordaos\"\n",
    "    EMBEDDING_MODEL_NAME = \"intfloat/multilingual-e5-large-instruct\" # Keep consistent\n",
    "\n",
    "try:\n",
    "    # Need data_loader to get data for indexing\n",
    "    from src.data_loader import load_and_prepare_data\n",
    "    print(\"Successfully imported from data_loader.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR importing from data_loader: {e}\")\n",
    "    load_and_prepare_data = None\n",
    "\n",
    "try:\n",
    "    # The module we are testing\n",
    "    from src.retriever import retrieve_relevant_chunks, _initialize_retriever\n",
    "    print(\"Successfully imported from retriever.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR importing from retriever: {e}\")\n",
    "    retrieve_relevant_chunks = None\n",
    "    _initialize_retriever = None # If needed for specific init tests\n",
    "\n",
    "# --- Third-party ---\n",
    "try:\n",
    "    import chromadb\n",
    "    print(\"Successfully imported chromadb.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR importing chromadb: {e}\")\n",
    "    chromadb = None\n",
    "\n",
    "\n",
    "# --- Helper Function for Cleanup ---\n",
    "# (Same as in indexer_tests)\n",
    "def cleanup_chroma_test_db(persist_dir=CHROMA_PERSIST_DIR):\n",
    "    \"\"\"Removes the ChromaDB test directory if it exists.\"\"\"\n",
    "    abs_persist_dir = os.path.abspath(persist_dir) # Use absolute path\n",
    "    if os.path.exists(abs_persist_dir):\n",
    "        print(f\"Cleaning up existing test ChromaDB directory: {abs_persist_dir}\")\n",
    "        try:\n",
    "            # Attempt to clear client cache if possible (might help with file locks)\n",
    "            # Note: This is speculative and depends on ChromaDB's internal state management\n",
    "            if 'src.retriever' in sys.modules:\n",
    "                 if hasattr(sys.modules['src.retriever'], '_chroma_client_instance') and \\\n",
    "                    sys.modules['src.retriever']._chroma_client_instance is not None:\n",
    "                     print(\"Attempting to reset cached ChromaDB client...\")\n",
    "                     # chromadb doesn't have an explicit close(), reset might clear internal state\n",
    "                     sys.modules['src.retriever']._chroma_client_instance.reset()\n",
    "                     sys.modules['src.retriever']._chroma_client_instance = None\n",
    "                     sys.modules['src.retriever']._chroma_collection_instance = None\n",
    "                     print(\"Cached client reset.\")\n",
    "                 else:\n",
    "                      print(\"No cached client found in retriever module to reset.\")\n",
    "\n",
    "\n",
    "            shutil.rmtree(abs_persist_dir)\n",
    "            print(\"Cleanup successful.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during cleanup: {e}. Manual deletion might be required.\")\n",
    "    else:\n",
    "        print(f\"Test ChromaDB directory not found (no cleanup needed): {abs_persist_dir}\")\n",
    "\n",
    "print(f\"\\nSetup complete. Using test ChromaDB directory: {os.path.abspath(CHROMA_PERSIST_DIR)}\")\n",
    "# Initial cleanup before tests start\n",
    "cleanup_chroma_test_db(CHROMA_PERSIST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:58:38,969 - RETRIEVER_TEST - INFO - Starting data loading and preparation for:\n",
      "2025-04-30 14:58:38,970 - RETRIEVER_TEST - INFO -   Acordão: f:\\interview\\acordao\\acordao_validator\\data\\Acórdão 733 de 2025 Plenário.pdf\n",
      "2025-04-30 14:58:38,971 - RETRIEVER_TEST - INFO -   Resumo: f:\\interview\\acordao\\acordao_validator\\data\\Acórdão 733-2025 resumos.txt\n",
      "2025-04-30 14:58:38,988 - RETRIEVER_TEST - INFO - Reading PDF: f:\\interview\\acordao\\acordao_validator\\data\\Acórdão 733 de 2025 Plenário.pdf with 44 pages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Running Pre-Test Indexing Setup ==========\n",
      "Attempting pre-setup cleanup...\n",
      "Test ChromaDB directory not found (no cleanup needed): f:\\interview\\acordao\\acordao_validator\\notebooks\\chroma_db_index\n",
      "\n",
      "Loading data using data_loader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:58:39,720 - RETRIEVER_TEST - INFO - Processing Acordão as PDF file.\n",
      "2025-04-30 14:58:39,721 - RETRIEVER_TEST - INFO - Processed 44 chunks from the acórdão.\n",
      "2025-04-30 14:58:39,722 - RETRIEVER_TEST - INFO - Processed 3 claims from the resumo.\n",
      "2025-04-30 14:58:39,811 - RETRIEVER_TEST - INFO - Loading embedding model 'intfloat/multilingual-e5-large-instruct' onto device: cuda\n",
      "2025-04-30 14:58:39,815 - RETRIEVER_TEST - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 44 acórdão chunks.\n",
      "\n",
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:58:45,884 - RETRIEVER_TEST - INFO - Embedding model 'intfloat/multilingual-e5-large-instruct' loaded successfully.\n",
      "2025-04-30 14:58:45,885 - RETRIEVER_TEST - INFO - Starting index creation/update process for 44 chunks...\n",
      "2025-04-30 14:58:45,885 - RETRIEVER_TEST - INFO - Initializing ChromaDB client at path: .\\chroma_db_index\n",
      "2025-04-30 14:58:45,924 - RETRIEVER_TEST - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-04-30 14:58:46,056 - RETRIEVER_TEST - INFO - Getting or creating collection: acordaos\n",
      "2025-04-30 14:58:46,087 - RETRIEVER_TEST - INFO - Preparing data for indexing (IDs, prefixed text, metadata)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
      "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "\n",
      "Running create_or_update_index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:58:46,088 - RETRIEVER_TEST - INFO - Generating embeddings for 44 chunks using model intfloat/multilingual-e5-large-instruct...\n",
      "Batches: 100%|██████████| 2/2 [00:05<00:00,  2.99s/it]\n",
      "2025-04-30 14:58:52,092 - RETRIEVER_TEST - INFO - Embedding generation complete.\n",
      "2025-04-30 14:58:52,093 - RETRIEVER_TEST - INFO - Upserting 44 items into ChromaDB collection 'acordaos'...\n",
      "2025-04-30 14:58:52,422 - RETRIEVER_TEST - INFO - Upsert completed successfully.\n",
      "2025-04-30 14:58:52,424 - RETRIEVER_TEST - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing function completed in 6.54 seconds.\n",
      "\n",
      "Verifying index existence...\n",
      "  ChromaDB directory found: f:\\interview\\acordao\\acordao_validator\\notebooks\\chroma_db_index\n",
      "  Connecting verification client...\n",
      "  Getting collection 'acordaos' for verification...\n",
      "  Collection 'acordaos' found with 44 items.\n",
      "  Setting verification client instance to None.\n",
      "\n",
      "-> SETUP COMPLETED SUCCESSFULLY\n",
      "\n",
      "========== End of Pre-Test Indexing Setup ==========\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Pre-Test Indexing Setup\n",
    "# We need to create an index first to test retrieval against it.\n",
    "\n",
    "print(\"\\n\" + \"=\"*10 + \" Running Pre-Test Indexing Setup \" + \"=\"*10)\n",
    "\n",
    "base_project_dir = os.path.abspath(os.path.join('..'))\n",
    "data_dir = os.path.join(base_project_dir, \"data\")\n",
    "persist_dir = os.path.abspath(CHROMA_PERSIST_DIR) # Use absolute path\n",
    "\n",
    "# --- Files to use ---\n",
    "# Using the same files as indexer_tests for consistency\n",
    "acordao_file = \"Acórdão 733 de 2025 Plenário.pdf\"\n",
    "resumo_file = \"Acórdão 733-2025 resumos.txt\" # Not used for indexing, but part of data loading\n",
    "acordao_path = os.path.join(data_dir, acordao_file)\n",
    "resumo_path = os.path.join(data_dir, resumo_file)\n",
    "\n",
    "# --- Global variable for the model instance ---\n",
    "# To pass it to the retriever tests if needed, and avoid reloading\n",
    "embedding_model_instance_for_retriever_test = None\n",
    "setup_successful = False\n",
    "\n",
    "# --- Check dependencies ---\n",
    "if None in [load_and_prepare_data, get_embedding_model, create_or_update_index]:\n",
    "    print(\"-> SETUP SKIPPED: Missing necessary functions due to import errors in Cell 2.\")\n",
    "elif not os.path.exists(acordao_path):\n",
    "     print(f\"-> SETUP SKIPPED: Acordao file not found at {acordao_path}\")\n",
    "else:\n",
    "    try:\n",
    "        # --- Ensure clean start ---\n",
    "        print(\"Attempting pre-setup cleanup...\")\n",
    "        cleanup_chroma_test_db(CHROMA_PERSIST_DIR) # Try cleanup before indexing\n",
    "\n",
    "        # 1. Load Data\n",
    "        print(f\"\\nLoading data using data_loader...\")\n",
    "        acordao_chunks, _ = load_and_prepare_data(acordao_path, resumo_path) # Only need chunks\n",
    "        if acordao_chunks is None or not acordao_chunks:\n",
    "            raise ValueError(\"Data loading failed or returned no chunks.\")\n",
    "        print(f\"Loaded {len(acordao_chunks)} acórdão chunks.\")\n",
    "\n",
    "        # 2. Load Model\n",
    "        print(\"\\nLoading embedding model...\")\n",
    "        # Use the function from indexer.py\n",
    "        embedding_model_instance_for_retriever_test = get_embedding_model()\n",
    "        if embedding_model_instance_for_retriever_test is None:\n",
    "             raise ValueError(\"Failed to load embedding model.\")\n",
    "        print(f\"Model loaded: {embedding_model_instance_for_retriever_test}\")\n",
    "\n",
    "        # 3. Run Indexer\n",
    "        print(\"\\nRunning create_or_update_index...\")\n",
    "        start_time = time.time()\n",
    "        # Use the function from indexer.py\n",
    "        create_or_update_index(acordao_chunks, embedding_model_instance_for_retriever_test)\n",
    "        index_time = time.time() - start_time\n",
    "        print(f\"Indexing function completed in {index_time:.2f} seconds.\")\n",
    "\n",
    "        # 4. Basic Verification (Check if DB exists and has items)\n",
    "        print(\"\\nVerifying index existence...\")\n",
    "        if not os.path.exists(persist_dir):\n",
    "             raise FileNotFoundError(f\"ChromaDB directory was not created at {persist_dir}\")\n",
    "        print(f\"  ChromaDB directory found: {persist_dir}\")\n",
    "        verify_client = None # Initialize to ensure finally block works\n",
    "        try:\n",
    "             print(f\"  Connecting verification client...\")\n",
    "             verify_client = chromadb.PersistentClient(path=persist_dir)\n",
    "             print(f\"  Getting collection '{CHROMA_COLLECTION_NAME}' for verification...\")\n",
    "             verify_collection = verify_client.get_collection(name=CHROMA_COLLECTION_NAME)\n",
    "             count = verify_collection.count()\n",
    "             if count != len(acordao_chunks):\n",
    "                 raise ValueError(f\"Index verification failed: Expected {len(acordao_chunks)} items, found {count}.\")\n",
    "             print(f\"  Collection '{CHROMA_COLLECTION_NAME}' found with {count} items.\")\n",
    "             # --- REMOVED verify_client.reset() ---\n",
    "             # print(\"  Verification client reset.\") # Not needed and causes error\n",
    "             setup_successful = True\n",
    "        except Exception as verify_e:\n",
    "             # Log the specific verification error\n",
    "             logging.error(f\"Error during index verification step: {verify_e}\", exc_info=True)\n",
    "             raise RuntimeError(f\"Error during index verification: {verify_e}\")\n",
    "        finally:\n",
    "             # Attempt to clean up the verification client instance\n",
    "             # Setting to None might help release resources, though not guaranteed for file locks\n",
    "             if verify_client is not None:\n",
    "                  print(\"  Setting verification client instance to None.\")\n",
    "                  verify_client = None\n",
    "\n",
    "\n",
    "        print(\"\\n-> SETUP COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"-> SETUP FAILED: {e}\")\n",
    "        # Cleanup if setup failed partially\n",
    "        print(\"Attempting cleanup after setup failure...\")\n",
    "        cleanup_chroma_test_db(CHROMA_PERSIST_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*10 + \" End of Pre-Test Indexing Setup \" + \"=\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:58:52,607 - RETRIEVER_TEST - INFO - Loading embedding model 'intfloat/multilingual-e5-large-instruct' onto device: cuda\n",
      "2025-04-30 14:58:52,611 - RETRIEVER_TEST - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Running Test: test_retrieval_logic ==========\n",
      "\n",
      "--- Test Case 1: Valid Query, Default top_k=3 ---\n",
      "Query: \"O BNDES é uma estatal dependente da União\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 14:58:58,451 - RETRIEVER_TEST - INFO - Embedding model 'intfloat/multilingual-e5-large-instruct' loaded successfully.\n",
      "2025-04-30 14:58:58,452 - RETRIEVER_TEST - INFO - Initializing ChromaDB client at path: .\\chroma_db_index\n",
      "2025-04-30 14:58:58,479 - RETRIEVER_TEST - INFO - Getting collection: acordaos\n",
      "2025-04-30 14:58:58,490 - RETRIEVER_TEST - INFO - Successfully connected to collection 'acordaos' with 44 items.\n",
      "2025-04-30 14:58:58,493 - RETRIEVER_TEST - INFO - Generating embedding for query: 'O BNDES é uma estatal dependente da União...'\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s]\n",
      "2025-04-30 14:58:58,570 - RETRIEVER_TEST - INFO - Querying collection 'acordaos' for top 3 results...\n",
      "2025-04-30 14:58:58,605 - RETRIEVER_TEST - INFO - Retrieved 3 results.\n",
      "2025-04-30 14:58:58,606 - RETRIEVER_TEST - INFO - Getting collection: acordaos\n",
      "2025-04-30 14:58:58,609 - RETRIEVER_TEST - INFO - Successfully connected to collection 'acordaos' with 44 items.\n",
      "2025-04-30 14:58:58,610 - RETRIEVER_TEST - INFO - Generating embedding for query: 'restituísse os valores recebidos a título de PLR...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 results.\n",
      "  Result 1 Distance: 0.1219\n",
      "  Result 1 Metadata: {'chunk_index': 31, 'chunk_type': 'paragraph', 'source': 'f:\\\\interview\\\\acordao\\\\acordao_validator\\\\data\\\\Acórdão 733 de 2025 Plenário.pdf', 'page_number': 32}\n",
      "  Result 1 Document Preview: TRIBUNAL DE CONTAS DA UNIÃO TC 004.980/2017-4 \n",
      " \n",
      "5 \n",
      " \n",
      "23. Pode-se afirmar, assim, que o fato de obte...\n",
      "-> Test Case 1 PASSED\n",
      "\n",
      "--- Test Case 2: Valid Query, Different top_k=5 ---\n",
      "Query: \"restituísse os valores recebidos a título de PLR\", top_k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.68it/s]\n",
      "2025-04-30 14:58:58,649 - RETRIEVER_TEST - INFO - Querying collection 'acordaos' for top 5 results...\n",
      "2025-04-30 14:58:58,654 - RETRIEVER_TEST - INFO - Retrieved 5 results.\n",
      "2025-04-30 14:58:58,655 - RETRIEVER_TEST - WARNING - Received empty query claim. Cannot retrieve.\n",
      "2025-04-30 14:58:58,656 - RETRIEVER_TEST - INFO - Getting collection: acordaos\n",
      "2025-04-30 14:58:58,660 - RETRIEVER_TEST - INFO - Successfully connected to collection 'acordaos' with 44 items.\n",
      "2025-04-30 14:58:58,662 - RETRIEVER_TEST - INFO - Generating embedding for query: 'Constituição Federal de 1988 artigo quinto inciso primeiro sobre alienígenas...'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5 results.\n",
      "-> Test Case 2 PASSED\n",
      "\n",
      "--- Test Case 3: Empty Query String ---\n",
      "Query: \"\"\n",
      "-> Test Case 3 PASSED (Returned None as expected)\n",
      "\n",
      "--- Test Case 4: Query Unlikely to Match ---\n",
      "Query: \"Constituição Federal de 1988 artigo quinto inciso primeiro sobre alienígenas\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.00it/s]\n",
      "2025-04-30 14:58:58,702 - RETRIEVER_TEST - INFO - Querying collection 'acordaos' for top 3 results...\n",
      "2025-04-30 14:58:58,704 - RETRIEVER_TEST - INFO - Retrieved 3 results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 results (expected 3).\n",
      "  Top result distance (likely high): 0.1679\n",
      "-> Test Case 4 PASSED (Returned results, even if poor matches)\n",
      "\n",
      "Result: ALL test_retrieval_logic tests PASSED\n",
      "\n",
      "========== End of Test: test_retrieval_logic ==========\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Test retrieve_relevant_chunks Function\n",
    "\n",
    "print(\"\\n\" + \"=\"*10 + \" Running Test: test_retrieval_logic \" + \"=\"*10)\n",
    "\n",
    "def test_retrieval_logic(model, collection_name):\n",
    "    \"\"\"\n",
    "    Tests the core logic of retrieve_relevant_chunks.\n",
    "    Assumes the index was successfully created in Cell 3.\n",
    "    \"\"\"\n",
    "    if retrieve_relevant_chunks is None:\n",
    "        print(\"SKIPPING test_retrieval_logic: retrieve_relevant_chunks function not imported.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Test Case 1: Valid Query, Default top_k=3 ---\")\n",
    "    # Use a claim from the Acórdão 733 resumos\n",
    "    query1 = \"O BNDES é uma estatal dependente da União\"\n",
    "    print(f\"Query: \\\"{query1}\\\"\")\n",
    "    results1 = retrieve_relevant_chunks(\n",
    "        query_claim=query1,\n",
    "        top_k=3,\n",
    "        model=model, # Pass the already loaded model\n",
    "        collection=None # Let the function initialize the collection connection\n",
    "    )\n",
    "\n",
    "    # --- Assertions for Valid Query ---\n",
    "    assert results1 is not None, \"Retrieval failed, returned None\"\n",
    "    assert isinstance(results1, dict), f\"Expected dict, got {type(results1)}\"\n",
    "    expected_keys = ['ids', 'embeddings', 'documents', 'metadatas', 'distances']\n",
    "    # Note: embeddings might be None if not included in the query's 'include' list in retriever.py\n",
    "    # Let's adjust based on retriever's include=['metadatas', 'documents', 'distances']\n",
    "    expected_keys = ['ids', 'documents', 'metadatas', 'distances']\n",
    "    for key in expected_keys:\n",
    "        assert key in results1, f\"Expected key '{key}' not in results\"\n",
    "        assert results1[key] is not None, f\"Key '{key}' is None\"\n",
    "        assert isinstance(results1[key], list), f\"Expected list for key '{key}', got {type(results1[key])}\"\n",
    "        # ChromaDB returns lists of lists, e.g., [[id1, id2]], [[doc1, doc2]]\n",
    "        assert len(results1[key]) == 1, f\"Expected outer list of size 1 for key '{key}'\"\n",
    "        assert isinstance(results1[key][0], list), f\"Expected inner list for key '{key}'\"\n",
    "\n",
    "    num_retrieved1 = len(results1['ids'][0])\n",
    "    print(f\"Retrieved {num_retrieved1} results.\")\n",
    "    # Check if number of results is <= top_k (might be fewer if collection has < k items)\n",
    "    assert num_retrieved1 <= 3, f\"Expected at most 3 results, got {num_retrieved1}\"\n",
    "    if num_retrieved1 > 0:\n",
    "         print(f\"  Result 1 Distance: {results1['distances'][0][0]:.4f}\")\n",
    "         print(f\"  Result 1 Metadata: {results1['metadatas'][0][0]}\")\n",
    "         print(f\"  Result 1 Document Preview: {results1['documents'][0][0][:100]}...\")\n",
    "    print(\"-> Test Case 1 PASSED\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Test Case 2: Valid Query, Different top_k=5 ---\")\n",
    "    query2 = \"restituísse os valores recebidos a título de PLR\" # Another claim\n",
    "    print(f\"Query: \\\"{query2}\\\", top_k=5\")\n",
    "    results2 = retrieve_relevant_chunks(query_claim=query2, top_k=5, model=model, collection=None) # Use cached model\n",
    "\n",
    "    assert results2 is not None, \"Retrieval failed\"\n",
    "    assert isinstance(results2, dict), \"Expected dict\"\n",
    "    num_retrieved2 = len(results2.get('ids', [[]])[0])\n",
    "    print(f\"Retrieved {num_retrieved2} results.\")\n",
    "    assert num_retrieved2 <= 5, f\"Expected at most 5 results, got {num_retrieved2}\"\n",
    "    print(\"-> Test Case 2 PASSED\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Test Case 3: Empty Query String ---\")\n",
    "    query3 = \"\"\n",
    "    print(f\"Query: \\\"{query3}\\\"\")\n",
    "    results3 = retrieve_relevant_chunks(query_claim=query3, top_k=3, model=model, collection=None)\n",
    "    assert results3 is None, f\"Expected None for empty query, got {type(results3)}\"\n",
    "    print(\"-> Test Case 3 PASSED (Returned None as expected)\")\n",
    "\n",
    "    print(\"\\n--- Test Case 4: Query Unlikely to Match ---\")\n",
    "    # Use a query very different from the Acordão content\n",
    "    query4 = \"Constituição Federal de 1988 artigo quinto inciso primeiro sobre alienígenas\"\n",
    "    print(f\"Query: \\\"{query4}\\\"\")\n",
    "    results4 = retrieve_relevant_chunks(query_claim=query4, top_k=3, model=model, collection=None)\n",
    "    assert results4 is not None, \"Retrieval should not fail for non-matching query, just return results\"\n",
    "    num_retrieved4 = len(results4.get('ids', [[]])[0])\n",
    "    # It WILL retrieve the closest matches, even if they are poor matches (high distance)\n",
    "    print(f\"Retrieved {num_retrieved4} results (expected {min(3, 44)}).\") # 44 is num chunks indexed\n",
    "    assert num_retrieved4 <= 3\n",
    "    if num_retrieved4 > 0:\n",
    "        print(f\"  Top result distance (likely high): {results4['distances'][0][0]:.4f}\")\n",
    "    print(\"-> Test Case 4 PASSED (Returned results, even if poor matches)\")\n",
    "\n",
    "\n",
    "# --- Run the Test ---\n",
    "if not setup_successful:\n",
    "     print(\"SKIPPING tests in Cell 4 because setup in Cell 3 failed.\")\n",
    "else:\n",
    "    try:\n",
    "        # Pass the model instance loaded during setup\n",
    "        test_retrieval_logic(embedding_model_instance_for_retriever_test, CHROMA_COLLECTION_NAME)\n",
    "        print(\"\\nResult: ALL test_retrieval_logic tests PASSED\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"\\nResult: TEST FAILED - Assertion Error: {e}\")\n",
    "    except Exception as e:\n",
    "         print(f\"\\nResult: TEST FAILED - Unexpected Error: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*10 + \" End of Test: test_retrieval_logic \" + \"=\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acordao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
